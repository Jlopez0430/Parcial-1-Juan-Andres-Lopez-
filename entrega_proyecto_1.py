# -*- coding: utf-8 -*-
"""Entrega Proyecto 1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v-fvpR5a2hqlNFTBOHvFZGWBYT9419nO

---
Autores:
 - Juan Pablo Arias Buitrago
 - Kevin Santiago Calder√≥n S√°nchez
 - Juan Andr√©s L√≥pez Escalante
 - Paula Andrea Vel√°squez Romero
 - Juan Jos√© √Ålvarez Ortiz
 ---

# **Entendimiento del Negocio**

* **Desigualdad educativa en Colombia**  
En Colombia, la calidad educativa presenta notables diferencias entre las grandes ciudades como Bogot√° y Medell√≠n, y ciudades m√°s peque√±as como Armenia y Neiva. Las ciudades m√°s peque√±as, ubicadas en regiones con menores recursos y oferta acad√©mica, enfrentan desaf√≠os significativos en comparaci√≥n con las principales urbes del pa√≠s.

* **Factores influyentes**  
Diversos factores, como el acceso a recursos educativos, la conectividad a Internet y el nivel socioecon√≥mico de las familias, influyen en los resultados de la prueba ICFES 11, evidenciando la desigualdad educativa en distintas zonas del pa√≠s.

* **Fuente de datos**  
El an√°lisis de esta situaci√≥n se basa en datos provenientes de fuentes oficiales y abiertas, como los datos abiertos de Colombia y el **DANE** (Departamento Administrativo Nacional de Estad√≠stica). Estos datos permiten realizar un an√°lisis detallado y contrastante, proporcionando una representaci√≥n objetiva de la situaci√≥n educativa en diferentes regiones del pa√≠s.

* **Indicadores macroecon√≥micos**  
Adem√°s de los datos educativos, se consideran indicadores macroecon√≥micos como el desempleo, la pobreza y la inversi√≥n p√∫blica para comprender mejor los desaf√≠os educativos espec√≠ficos de cada regi√≥n.

---

# An√°lisis Exploratorio de Datos (EDA)

El An√°lisis Exploratorio de Datos (EDA) es una fase clave en el an√°lisis de datos que nos ayuda a comprender el comportamiento del conjunto de datos. Su objetivo es:

1. **Detectar datos at√≠picos**: Identificar valores que se desv√≠an significativamente de la norma y decidir si se deben eliminar o investigar.

2. **Encontrar valores nulos**: Localizar datos faltantes para evaluar c√≥mo afectan al an√°lisis y decidir c√≥mo manejarlos.

3. **Identificar patrones y tendencias**: Descubrir relaciones entre variables y comportamientos generales dentro del conjunto de datos.

4. **Revisar distribuciones**: Analizar la distribuci√≥n de las variables para entender su comportamiento y detectar sesgos.

5. **Obtener estad√≠sticas descriptivas**: Resumir las principales caracter√≠sticas de los datos, como la media, mediana y desviaci√≥n est√°ndar.
"""

# Importar las librerias
import pandas as pd
import numpy as np
from pandas import DataFrame

# Visualizaci√≥n de datos
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import matplotlib.ticker as mticker

# Matem√°ticas, tiempo, manipulaci√≥n
import math
import time
import os

# Drive
from google.colab import drive
drive.mount('/content/drive')

!ls "/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Estadisticas_educacion_2016-2022.csv"

# Ruta de los diccionarios de datos en Google Drive
file_path1 = '/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Estadisticas_educacion_2016-2022.csv'
file_path2 = '/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Estadisticas_matriculas_2016-2020.csv'
file_path3 = '/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Inversion_municipal_Duque.csv'
file_path4 = '/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Penetracion_internet_2016-2022.csv'
file_path5 = '/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Indice_pobreza_2019-2022.csv'
file_path6 = '/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Resultados_Saber11_armenia.csv'
file_path7 = '/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Resultados_Saber11_bogota.csv'
file_path8 = '/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Resultados_Saber11_medellin.csv'
file_path9 = '/content/drive/MyDrive/PROCESAMIENTO_BIG_DATA/Resultados_Saber11_neiva.csv'

# Cargar el archivo desde Google Drive
educacion = pd.read_csv(file_path1)
matriculas = pd.read_csv(file_path2)
inversion = pd.read_csv(file_path3)
internet = pd.read_csv(file_path4)
pobreza = pd.read_csv(file_path5)
icfes_armenia = pd.read_csv(file_path6)
icfes_bogota = pd.read_csv(file_path7)
icfes_medellin = pd.read_csv(file_path8)
icfes_neiva = pd.read_csv(file_path9)

"""---
## **üõú Internet por Municipio**

### üìöDescripci√≥n general del contenido de los conjuntos de datos
- Los conjuntos de datos incluyen informaci√≥n sobre el acceso a Internet fijo en Colombia, detallando el n√∫mero de suscriptores con conexi√≥n dedicada por departamento y municipio, con reportes trimestrales desde 2015-4T hasta el √∫ltimo trimestre disponible. Adem√°s, presentan el porcentaje de penetraci√≥n de Internet fijo, calculado con base en las proyecciones de poblaci√≥n del DANE. Tambi√©n contienen datos sobre la Matr√≠cula en Educaci√≥n Superior, desagregados por nivel de formaci√≥n y municipio, permitiendo el an√°lisis de su distribuci√≥n y evoluci√≥n en el pa√≠s.
"""

# Mostrar las primeras filas del dataset
display(internet.head())

# Mostrar la cantidad de filas y columnas
print("El tama√±o del Datframe es:" ,internet.shape)

"""### **üìå Compresi√≥n de los Atributos del Dataset**

## üìÖ Datos Generales
- **A√ëO** (`a_o`): Representa el a√±o en el que se registraron los datos.  
- **TRIMESTRE** (`trimestre`): Indica el trimestre del a√±o correspondiente a la informaci√≥n recolectada.  

## üó∫Ô∏è Ubicaci√≥n Geogr√°fica
- **COD_DEPARTAMENTO** (`cod_departamento`): C√≥digo √∫nico que identifica el departamento seg√∫n la clasificaci√≥n oficial.  
- **DEPARTAMENTO** (`departamento`): Nombre del departamento donde se registraron los datos.  
- **COD_MUNICIPIO** (`cod_municipio`): C√≥digo √∫nico asignado a cada municipio.  
- **MUNICIPIO** (`municipio`): Nombre del municipio al que corresponden los datos.  

## üåê Conectividad a Internet
- **No. ACCESOS FIJOS A INTERNET** (`no_accesos_fijos_a_internet`): Cantidad de accesos fijos a internet registrados en el municipio.  
- **POBLACI√ìN DANE** (`poblaci_n_dane`): N√∫mero total de habitantes en el municipio seg√∫n los datos del DANE.  
- **INDICE** (`indice`): M√©trica que refleja el nivel de penetraci√≥n de internet fijo en el municipio, calculada con base en la poblaci√≥n y el n√∫mero de accesos.

### **üî¢ Tipos de Datos üî†**
"""

#Identificar las variables del dataset
print("Las variables del dataset son: \n")
print(internet.dtypes)

"""### **üìä Analisis Estad√≠stico y Gr√°ficos**

###**Estad√≠sticas** **generales**
"""

# Obtener estad√≠sticas generales de las columnas n√∫mericas
estadisticas = internet.describe()

# Mostrar estad√≠sticas
print(estadisticas)

#Valores nulos
internet.isnull().sum()

#Valores √∫nicos
internet.nunique()

# Contar registros duplicados en todo el dataset
duplicados = internet.duplicated()
print(f"Total de filas duplicadas: {duplicados.sum()}")

internet['No. ACCESOS FIJOS A INTERNET'].max()

internet['No. ACCESOS FIJOS A INTERNET'].min()

"""###**Gr√°ficas**"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Cargar el dataset (ajusta seg√∫n sea necesario)
# df = pd.read_csv("archivo.csv")

# Seleccionar las variables num√©ricas relevantes
variables_relevantes = [
    "No. ACCESOS FIJOS A INTERNET",
    "POBLACI√ìN DANE",
    "A√ëO"
]

# Filtrar solo las columnas num√©ricas relevantes y eliminar valores nulos
df_numeric = internet[variables_relevantes].dropna()

# Crear la figura y los subgr√°ficos
fig, axes = plt.subplots(nrows=1, ncols=len(variables_relevantes), figsize=(18, 6))

# Generar boxplots para cada variable
for i, col in enumerate(variables_relevantes):
    sns.boxplot(y=df_numeric[col], ax=axes[i], color="lightblue")
    axes[i].set_title(f' {col}')
    axes[i].set_ylabel("Valores")

# Ajustar el espacio entre gr√°ficos
plt.tight_layout()
plt.show()

"""El an√°lisis de los boxplots muestra que tanto los accesos fijos a internet como la poblaci√≥n municipal tienen distribuciones sesgadas con valores at√≠picos altos, indicando que unos pocos municipios concentran gran parte de la conectividad y la poblaci√≥n. La mayor√≠a de los municipios tienen bajos accesos a internet en relaci√≥n con su poblaci√≥n. En contraste, la variable A√ëO est√° uniformemente distribuida entre 2016 y 2022, sin valores extremos. Esto sugiere una cobertura de datos consistente en el tiempo, mientras que la conectividad muestra desigualdades significativas entre municipios."""

#N√∫mero de Accesos fijos a internet por Municipio

internet_sorted = internet.sort_values(by="No. ACCESOS FIJOS A INTERNET", ascending=False)
plt.figure(figsize=(12, 6))
sns.barplot(data=internet_sorted, x="MUNICIPIO", y="No. ACCESOS FIJOS A INTERNET", palette="Blues_r")
plt.xlabel("Municipio")
plt.ylabel("N√∫mero de Accesos Fijos a Internet")
plt.title("Accesos Fijos a Internet por Municipio")
plt.ticklabel_format(style="plain", axis="y")
plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{int(x):,}'))# eje Y en miles
plt.show()

"""La gr√°fica muestra el n√∫mero de accesos fijos a internet en distintos municipios, destacando una fuerte concentraci√≥n en Bogot√°, D.C., seguido por Medell√≠n, mientras que Neiva y Armenia tienen valores significativamente m√°s bajos. Esta distribuci√≥n es esperada debido a la relaci√≥n positiva entre la poblaci√≥n y el acceso a internet, como se observ√≥ en la matriz de correlaci√≥n. Bogot√°, al ser la ciudad m√°s grande del pa√≠s, lidera en cantidad de accesos, mientras que Medell√≠n, otro centro urbano importante, ocupa el segundo lugar."""

#Poblaci√≥n por municipios

plt.figure(figsize=(12, 6))
sns.barplot(data=poblacion_sorted, x="MUNICIPIO", y="POBLACI√ìN DANE", palette="viridis")
plt.xticks(rotation=90)
plt.xlabel("Municipio")
plt.ylabel("Poblaci√≥n")
plt.title("Poblaci√≥n por Municipio")
plt.ticklabel_format(style="plain", axis="y")
plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{int(x):,}'))
plt.show()

#El incremento del acceso a internet a traves de los a√±os

internet_por_a√±o = internet.groupby("A√ëO")["No. ACCESOS FIJOS A INTERNET"].sum().reset_index() #suma total de accesos de todos los municipios.
plt.figure(figsize=(10, 5))
sns.lineplot(data=internet_por_a√±o, x="A√ëO", y="No. ACCESOS FIJOS A INTERNET", marker="o", linewidth=2, color="b")
plt.xlabel("A√±o")
plt.ylabel("N√∫mero de Accesos Fijos a Internet")
plt.title("Evoluci√≥n de Accesos Fijos a Internet por A√±o")
plt.ticklabel_format(style="plain", axis="y")
plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{int(x):,}'))
plt.show()

"""La gr√°fica muestra la evoluci√≥n del n√∫mero de accesos fijos a internet entre los a√±os 2016 y 2022. Se observa una tendencia general al alza, con un crecimiento significativo desde 2016 hasta 2017, seguido de una leve disminuci√≥n en 2018. A partir de 2019, la cantidad de accesos vuelve a aumentar de manera sostenida, alcanzando su punto m√°s alto en 2022."""

#Matriz correlaci√≥n
df_numeric = internet.drop(columns=["DEPARTAMENTO", "MUNICIPIO"], errors="ignore")# Eliminar variables categ√≥ricas
correlation_matrix = df_numeric.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Matriz de Correlaci√≥n - Dataset Internet")
plt.show()

"""En general, la gr√°fica sugiere que la disponibilidad de internet est√° fuertemente ligada al tama√±o de la poblaci√≥n, mientras que otros factores tienen menor impacto en la variabilidad de los accesos.

---
## **Educaci√≥n por Municipio**

### üìöDescripci√≥n general del contenido de los conjuntos de datos  }
- Los conjuntos de datos contienen informaci√≥n estad√≠stica sobre educaci√≥n en los niveles preescolar, b√°sica y media en municipios de Colombia, desde 2011 hasta 2023, excluyendo valores at√≠picos. Incluyen indicadores sectoriales clave, como tasas de cobertura bruta y neta, calculadas con proyecciones del Censo 2018 para 2018 y 2019. Los valores est√°n en formato decimal en la base de datos, pero se exportan multiplicados por 100 para expresarlos como porcentajes.
"""

# Mostrar las primeras filas del dataset
display(educacion.head())

# Mostrar la cantidad de filas y columnas
educacion.shape

"""### **üìå Compresi√≥n de los Atributos del Dataset**
## üìÖ Datos Generales
- **A√ëO** (`a_o`): Representa el a√±o en el que se registraron los datos.
- **C√ìDIGO_MUNICIPIO** (`c_digo_municipio`): C√≥digo DANE del municipio.
- **MUNICIPIO** (`municipio`): Nombre del municipio.
- **C√ìDIGO_DEPARTAMENTO** (`c_digo_departamento`): C√≥digo DANE del departamento.
- **DEPARTAMENTO** (`departamento`): Nombre del departamento.
- **C√ìDIGO_ETC** (`c_digo_etc`): C√≥digo DANE de la ETC.
- **ETC** (`etc`): Nombre de la ETC.

## üåç Demograf√≠a Educativa
- **POBLACI√ìN_5_16** (`poblaci_n_5_16`): Poblaci√≥n en edad te√≥rica de estudiar (5 a 16 a√±os) seg√∫n proyecciones del DANE.
- **TASA_MATRICULACI√ìN_5_16** (`tasa_matriculaci_n_5_16`): Proporci√≥n de la poblaci√≥n entre 5 y 16 a√±os que asiste al sistema educativo. Puede ser mayor al 100% por flujos migratorios.

## üìä Cobertura Educativa
- **COBERTURA_NETA** (`cobertura_neta`): Relaci√≥n entre estudiantes matriculados en transici√≥n, primaria, secundaria y media con edad te√≥rica y la poblaci√≥n total correspondiente.
- **COBERTURA_NETA_TRANSICI√ìN** (`cobertura_neta_transici_n`): Relaci√≥n entre estudiantes matriculados en transici√≥n con edad te√≥rica y la poblaci√≥n total correspondiente.
- **COBERTURA_NETA_PRIMARIA** (`cobertura_neta_primaria`): Relaci√≥n entre estudiantes matriculados en primaria con edad te√≥rica y la poblaci√≥n total correspondiente.
- **COBERTURA_NETA_SECUNDARIA** (`cobertura_neta_secundaria`): Relaci√≥n entre estudiantes matriculados en secundaria con edad te√≥rica y la poblaci√≥n total correspondiente.
- **COBERTURA_NETA_MEDIA** (`cobertura_neta_media`): Relaci√≥n entre estudiantes matriculados en media con edad te√≥rica y la poblaci√≥n total correspondiente.
- **COBERTURA_BRUTA** (`cobertura_bruta`): Relaci√≥n entre estudiantes matriculados en transici√≥n, primaria, secundaria y media y la poblaci√≥n en edad te√≥rica para estos niveles.

## üè´ Calidad y Infraestructura Educativa
- **TAMA√ëO_PROMEDIO_DE_GRUPO** (`tama_o_promedio_de_grupo`): N√∫mero promedio de estudiantes por grupo considerando el sector oficial y no oficial.
- **SEDES_CONECTADAS_A_INTERNET** (`sedes_conectadas_a_internet`): Porcentaje de sedes oficiales de una Entidad Territorial Certificada conectadas a internet.

## üìâ Indicadores de Desempe√±o Acad√©mico
- **DESERCI√ìN** (`deserci_n`): Tasa de deserci√≥n intraanual del sector oficial, indica alumnos que abandonan estudios durante el a√±o.
- **APROBACI√ìN** (`aprobaci_n`): Tasa de aprobaci√≥n de estudiantes del sector oficial en educaci√≥n preescolar, b√°sica y media.
- **REPROBACI√ìN** (`reprobaci_n`): Tasa de reprobaci√≥n de estudiantes del sector oficial en educaci√≥n preescolar, b√°sica y media.
- **REPITENCIA** (`repitencia`): Tasa de repitencia del sector oficial, porcentaje de alumnos que repiten grado del a√±o anterior.

### **üî¢ Tipos de Datos üî†**
"""

#Identificar las variables del dataset
print("Las variables del dataset son: \n")
print(educacion.dtypes)

"""### **üìä Analisis Estad√≠stico y Gr√°ficos**

###**Estad√≠sticas** **generales**
"""

# Obtener estad√≠sticas generales de las columnas n√∫mericas
educacion.describe()

#Valores nulos
educacion.isnull().sum()

#Valores √∫nicos
educacion.nunique()

# Contar registros duplicados en todo el dataset
duplicados = educacion.duplicated()
print(f"Total de filas duplicadas: {duplicados.sum()}")

"""###**Gr√°ficas**"""

# Seleccionar las variables num√©ricas m√°s relevantes
variables_relevantes = [
    'POBLACI√ìN_5_16', 'TASA_MATRICULACI√ìN_5_16', 'COBERTURA_NETA', 'SEDES_CONECTADAS_A_INTERNET', 'DESERCI√ìN',
    'APROBACI√ìN', 'REPROBACI√ìN', 'REPITENCIA','TAMA√ëO_PROMEDIO_DE_GRUPO','A√ëO'
]

# Filtrar solo las columnas num√©ricas relevantes
df_numeric = educacion[variables_relevantes].dropna()

# Crear la figura y los subgr√°ficos
fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(18, 10))

# Aplanar la matriz de ejes para facilitar la iteraci√≥n
axes = axes.flatten()

# Generar un boxplot por variable num√©rica
for i, col in enumerate(variables_relevantes):
    sns.boxplot(y=df_numeric[col], ax=axes[i], color="lightblue")
    axes[i].set_title(f' {col}')
    axes[i].set_ylabel("Valores")

# Ajustar el espacio entre gr√°ficos
plt.tight_layout()
plt.show()

"""El gr√°fico muestra la distribuci√≥n de diversas variables educativas mediante diagramas de caja. Se observa que la poblaci√≥n entre 5 y 16 a√±os var√≠a significativamente entre regiones, con algunos valores at√≠picos elevados. La tasa de matriculaci√≥n y cobertura neta son altas, pero presentan variabilidad en ciertas √°reas. La conectividad a internet en sedes educativas es desigual, con una mediana en torno al 50%. La deserci√≥n se mantiene en niveles bajos (3.5%-6.5%), mientras que la aprobaci√≥n ronda el 86%, aunque con tasas de reprobaci√≥n y repitencia moderadas en algunas regiones."""

#Deserci√≥n por Municipio


desercion_cols = ["DESERCI√ìN_TRANSICI√ìN", "DESERCI√ìN_PRIMARIA", "DESERCI√ìN_SECUNDARIA", "DESERCI√ìN_MEDIA"]
df_desercion = educacion.groupby("MUNICIPIO")[desercion_cols].mean().reset_index()
df_melted = df_desercion.melt(id_vars=["MUNICIPIO"],
                              var_name="Nivel Educativo",
                              value_name="Tasa de Deserci√≥n")

df_melted["Nivel Educativo"] = df_melted["Nivel Educativo"].replace({
    "DESERCI√ìN_TRANSICI√ìN": "Transici√≥n",
    "DESERCI√ìN_PRIMARIA": "Primaria",
    "DESERCI√ìN_SECUNDARIA": "Secundaria",
    "DESERCI√ìN_MEDIA": "Media"
})

# Filtrar solo los municipios con mayor tasa de deserci√≥n promedio
top_municipios = df_desercion.set_index("MUNICIPIO").mean(axis=1).nlargest(10).index
df_melted_top = df_melted[df_melted["MUNICIPIO"].isin(top_municipios)]


plt.figure(figsize=(12,6))
sns.barplot(data=df_melted_top, x="MUNICIPIO", y="Tasa de Deserci√≥n", hue="Nivel Educativo", palette="magma")
plt.title("Tasa de Deserci√≥n por Municipio y Nivel Educativo", fontsize=14)
plt.xlabel("Municipio")
plt.ylabel("Tasa de Deserci√≥n (%)")
plt.xticks(rotation=45, ha="right")
plt.legend(title="Nivel Educativo")
plt.grid(axis="y", linestyle="--", alpha=0.6)
plt.show()

"""El gr√°fico muestra la tasa de deserci√≥n escolar por municipio y nivel educativo. Se observa que Neiva y Armenia tienen los valores m√°s altos, especialmente en secundaria, con tasas que superan el 6%. Medell√≠n presenta tasas intermedias, con un pico en secundaria, mientras que Bogot√° D.C. tiene la deserci√≥n m√°s baja en todos los niveles, con valores cercanos al 1%. En general, la secundaria es el nivel con mayor deserci√≥n en la mayor√≠a de los municipios, mientras que la transici√≥n y la educaci√≥n media presentan tasas m√°s moderadas."""

#Indicadores por nivel educativo

indicadores = {
    "Aprobaci√≥n": ["APROBACI√ìN_TRANSICI√ìN", "APROBACI√ìN_PRIMARIA", "APROBACI√ìN_SECUNDARIA", "APROBACI√ìN_MEDIA"],
    "Deserci√≥n": ["DESERCI√ìN_TRANSICI√ìN", "DESERCI√ìN_PRIMARIA", "DESERCI√ìN_SECUNDARIA", "DESERCI√ìN_MEDIA"],
    "Reprobaci√≥n": ["REPROBACI√ìN_TRANSICI√ìN", "REPROBACI√ìN_PRIMARIA", "REPROBACI√ìN_SECUNDARIA", "REPROBACI√ìN_MEDIA"]
}

# Crear un DataFrame con los promedios de cada indicador
data = {indicador: [educacion[col].mean() for col in columnas] for indicador, columnas in indicadores.items()}
niveles_educativos = ["Transici√≥n", "Primaria", "Secundaria", "Media"]

# Crear el gr√°fico
plt.figure(figsize=(10,6))
df_plot = pd.DataFrame(data, index=niveles_educativos)
df_plot.plot(kind="bar", figsize=(10,6), colormap="viridis", alpha=0.85)

# Personalizaci√≥n del gr√°fico
plt.title("Comparaci√≥n de Indicadores por Nivel Educativo", fontsize=14)
plt.xlabel("Nivel Educativo")
plt.ylabel("Porcentaje (%)")
plt.xticks(rotation=0)
plt.legend(title="Indicador")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

"""El gr√°fico muestra que la aprobaci√≥n es el indicador predominante en todos los niveles educativos, con valores superiores al 80%, aunque disminuye ligeramente en secundaria. La deserci√≥n se mantiene baja y sin variaciones significativas. La reprobaci√≥n, en cambio, es m√°s baja en transici√≥n y primaria, aumenta notablemente en secundaria y disminuye nuevamente en media. Esto sugiere que la secundaria es la etapa con mayores desaf√≠os acad√©micos para los estudiantes."""

#Poblaci√≥n por municipio y tasa de matriculaci√≥n

df_sorted = educacion.sort_values("POBLACI√ìN_5_16", ascending=False)
fig, ax1 = plt.subplots(figsize=(10, 6))

# Gr√°fico de barras para la poblaci√≥n
sns.barplot(x="MUNICIPIO", y="POBLACI√ìN_5_16", data=df_sorted, color="skyblue", ax=ax1)
ax1.set_ylabel("Poblaci√≥n (5-16 a√±os)", color="blue")
ax1.tick_params(axis='y', labelcolor="blue")
ax1.set_xticklabels(ax1.get_xticklabels())  # Rotar nombres de municipios

# Quitar notaci√≥n cient√≠fica del eje Y
ax1.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f"{int(x):,}"))

# Crear segundo eje Y para la tasa de matriculaci√≥n
ax2 = ax1.twinx()
sns.lineplot(x="MUNICIPIO", y="TASA_MATRICULACI√ìN_5_16", data=df_sorted, color="red", marker="o", ax=ax2)
ax2.set_ylabel("Tasa de Matriculaci√≥n (%)", color="red")
ax2.tick_params(axis='y', labelcolor="red")

# Quitar notaci√≥n cient√≠fica del eje Y secundario
ax2.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f"{x:.2f}"))

# T√≠tulo y grid
plt.title("Poblaci√≥n por Municipio y Tasa de Matriculaci√≥n")
ax1.grid(True, linestyle="--", alpha=0.5)

# Mostrar gr√°fico
plt.show()

"""El gr√°fico muestra la poblaci√≥n de ni√±os y adolescentes entre 5 y 16 a√±os por municipio (barras azules, eje izquierdo) y la tasa de matriculaci√≥n correspondiente (l√≠nea roja, eje derecho). Bogot√° D.C. tiene la poblaci√≥n m√°s alta, superando 1.2 millones, y una tasa de matriculaci√≥n cercana al 100%. Medell√≠n, con una poblaci√≥n significativamente menor, tambi√©n mantiene una tasa alta. Neiva, a pesar de tener una poblaci√≥n mucho menor que Bogot√°, presenta una tasa de matriculaci√≥n ligeramente superior, lo que sugiere una mayor cobertura proporcional en el sistema educativo. En contraste, Armenia tiene la poblaci√≥n m√°s baja y la menor tasa de matriculaci√≥n, cercana al 75%.

---
## **√çndice de Pobreza de Hogares por Persona**

### üìöDescripci√≥n general del contenido de los conjuntos de datos
- Los conjuntos de datos contienen informaci√≥n detallada sobre diversos aspectos sociodemogr√°ficos, educativos, laborales y de salud de la poblaci√≥n en Colombia. Incluyen variables clave como **identificadores √∫nicos** (directorio, secuencia de encuesta, orden), caracter√≠sticas personales (**edad, alfabetizaci√≥n, nivel educativo alcanzado, matr√≠cula actual**), condiciones de salud (**afiliaci√≥n a seguridad social, acceso a servicios m√©dicos, alimentaci√≥n escolar**), y aspectos laborales (**ocupaci√≥n principal, b√∫squeda de empleo, cotizaci√≥n a pensiones**). Esta informaci√≥n permite realizar an√°lisis sobre la cobertura educativa, acceso a servicios de salud, condiciones laborales y bienestar social, facilitando la toma de decisiones y la formulaci√≥n de pol√≠ticas p√∫blicas.
"""

# Mostrar las primeras filas del dataset
display(pobreza.head())

# Mostrar la cantidad de filas y columnas
pobreza.shape

"""### **üìå Compresi√≥n de los Atributos del Dataset**
## üìÇ Identificaci√≥n y Secuencia
- **DIRECTORIO** (`directorio`): Identificador del directorio de la encuesta.  
- **SECUENCIA_ENCUESTA** (`secuencia_encuesta`): N√∫mero de secuencia de la encuesta.  
- **SECUENCIA_P** (`secuencia_p`): N√∫mero de secuencia de la persona dentro del hogar.  
- **ORDEN** (`orden`): Orden de la persona en la encuesta.  

## üë§ Informaci√≥n Demogr√°fica
- **P6020** (`P6020`): G√©nero de la persona.  
- **P6040** (`P6040`): ¬øCu√°ntos a√±os cumplidos tiene?  
- **FEX_C** (`fex_c`): Factor de expansi√≥n de la encuesta.  

## üè• Salud
- **P6051** (`P6051`): Estado de salud general.  
- **P6090** (`P6090`): ¬øEst√° afiliado, es cotizante o es beneficiario de alguna entidad de seguridad social en salud? (EPS o ARS - Sisben).  
- **P5665** (`P5665`): En los √∫ltimos 30 d√≠as, ¬øtuvo alguna enfermedad, accidente, problema odontol√≥gico u otro problema de salud que no haya implicado hospitalizaci√≥n?  
- **P8563** (`P8563`): Para tratar ese problema de salud, ¬øqu√© hizo principalmente?  

## üè† Condiciones de Vida
- **P51** (`P51`): ¬øD√≥nde o con qui√©n permanece la mayor parte del tiempo entre semana?  
- **P55** (`P55`): ¬øRecibe o toma desayuno o almuerzo en el lugar donde permanece la mayor parte del tiempo entre semana?  
- **P774** (`P774`): ¬øQui√©n paga por esta alimentaci√≥n?  

## üìñ Educaci√≥n
- **P6160** (`P6160`): ¬øSabe leer y escribir?  
- **P8586** (`P8586`): ¬øActualmente estudia? (Asiste al preescolar, escuela, colegio o universidad).  
- **P8587** (`P8587`): ¬øCu√°l es el nivel educativo m√°s alto alcanzado y el √∫ltimo a√±o o grado aprobado en este nivel?  
- **P8587S1** (`P8587S1`): Grado o a√±o aprobado.  
- **P1088** (`P1088`): ¬øEn qu√© nivel est√° matriculado y qu√© grado cursa?  
- **P1088S1** (`P1088S1`): Grado o a√±o que cursa.  
- **P6180** (`P6180`): ¬øRecibe en el plantel educativo alimentos en forma gratuita o por un pago simb√≥lico?  

## üíº Ocupaci√≥n y Trabajo
- **P6240** (`P6240`): ¬øEn qu√© actividad ocup√≥ la mayor parte del tiempo la semana pasada?  
- **P6250** (`P6250`): Adem√°s de lo anterior, ¬ørealiz√≥ alguna actividad paga por una hora o m√°s?  
- **P6260** (`P6260`): Aunque no trabaj√≥ la semana pasada por una hora o m√°s en forma remunerada, ¬øten√≠a alg√∫n trabajo o negocio por el que recibe ingresos?  
- **P6270** (`P6270`): ¬øTrabaj√≥ la semana pasada en un negocio por una hora o m√°s sin que le pagaran?  
- **P6351** (`P6351`): Si le hubiera resultado alg√∫n trabajo, ¬øestaba disponible la semana pasada para empezar a trabajar?  
- **P6390S1** (`P6390S1`): ¬øA qu√© actividad se dedica principalmente la empresa o negocio en la que realiza su trabajo?  
- **P7250** (`P7250`): ¬øDurante cu√°ntas semanas ha estado buscando trabajo?  
- **P6920** (`P6920`): ¬øEst√° cotizando actualmente a un fondo de pensiones?

### **üî¢ Tipos de Datos üî†**
"""

#Identificar las variables del dataset
print("Las variables del dataset son: \n")
print(pobreza.dtypes)

"""### **üìä Analisis Estad√≠stico y Gr√°ficos**

###**Estad√≠sticas** **generales**
"""

# Obtener estad√≠sticas generales de las columnas n√∫mericas
pobreza.describe()

#Valores nulos
pobreza.isnull().sum()

#Valores √∫nicos
pobreza.nunique()

# Contar registros duplicados en todo el dataset
duplicados = internet.duplicated()
print(f"Total de filas duplicadas: {duplicados.sum()}")

"""###**Gr√°ficas**"""

#Distribuci√≥n del genero
plt.figure(figsize=(6, 4))
sns.countplot(x="P6020", data=pobreza, palette="pastel")
plt.xlabel("G√©nero")
plt.ylabel("Cantidad de Personas")
plt.title("Distribuci√≥n de G√©nero en la Encuesta")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Diccionario de t√≠tulos descriptivos
titulos = {
    "P6040": "Distribuci√≥n de la Edad",
    "P8587": "Nivel Educativo Alcanzado",
    "P6090": "Afiliaci√≥n a Seguridad Social en Salud",
    "P8587S1": "Grado aprobado",
    "P8586": "Estudia Actualmente",
    "P6180":"Alimento del Plantel educativo",
}

# Seleccionar las variables m√°s relevantes
variables_relevantes = list(titulos.keys())

# Convertir a num√©rico, ignorando errores
pobreza_numeric = pobreza[variables_relevantes].apply(pd.to_numeric, errors="coerce")

# Crear la figura y subgr√°ficos
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))
axes = axes.flatten()  # Convertir en una lista para iterar f√°cilmente

# Generar los histogramas con t√≠tulos descriptivos
for i, col in enumerate(variables_relevantes):
    if i < len(axes):
        axes[i].hist(pobreza_numeric[col].dropna(), bins=20, color="skyblue", edgecolor="black", alpha=0.7)
        axes[i].set_title(titulos[col])  # Usar el t√≠tulo descriptivo
        axes[i].set_xlabel(titulos[col])
        axes[i].set_ylabel("Frecuencia")

# Ajustar la distribuci√≥n de los gr√°ficos
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Diccionario de t√≠tulos descriptivos
titulos = {
    "P6040": "Distribuci√≥n de la Edad",
    "P8587": "Nivel Educativo Alcanzado",
    "P6090": "Afiliaci√≥n a Seguridad Social en Salud",
    "P8587S1": "Grado aprobado",
    "P8586": "Estudia Actualmente",
    "P6180":"Alimento del Plantel educativo",
}


# Seleccionar las variables m√°s relevantes
variables_relevantes = list(titulos.keys())

# Convertir a num√©rico, ignorando errores
pobreza_numeric = pobreza[variables_relevantes].apply(pd.to_numeric, errors="coerce")

# Crear la figura y subgr√°ficos
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))
axes = axes.flatten()  # Convertir en una lista para iterar f√°cilmente

# Generar los boxplots con t√≠tulos descriptivos
for i, col in enumerate(variables_relevantes):
    if i < len(axes):
        sns.boxplot(y=pobreza_numeric[col], ax=axes[i], color="lightblue")
        axes[i].set_title(titulos[col])  # Usar el t√≠tulo descriptivo
        axes[i].set_ylabel(titulos[col])

# Ajustar la distribuci√≥n de los gr√°ficos
plt.tight_layout()
plt.show()

"""### **üìù Calidad de Datos**

---
## **Ficha de Inversi√≥n Municipal en Proyectos P√∫blicos (PP)**

### üìöDescripci√≥n general del contenido de los conjuntos de datos
- Los conjuntos de datos presentan informaci√≥n sobre la inversi√≥n y gesti√≥n de programas sociales del Gobierno Nacional a nivel municipal, organizados por periodos presidenciales. Incluyen detalles sobre los recursos destinados a la atenci√≥n de poblaci√≥n vulnerable y v√≠ctimas, as√≠ como las acciones implementadas para su bienestar. Adem√°s, registran las entidades que conforman el **Sector de Inclusi√≥n Social y la Reconciliaci√≥n, permitiendo analizar la distribuci√≥n de la inversi√≥n, el impacto de las pol√≠ticas p√∫blicas y la evoluci√≥n de estos programas en los distintos municipios del pa√≠s.
"""

# Mostrar las primeras filas del dataset
display(inversion.head())

# Mostrar la cantidad de filas y columnas
inversion.shape

"""### **üìå Compresi√≥n de los Atributos del Dataset**
## üó∫Ô∏è Ubicaci√≥n Geogr√°fica
- **C√≥digo Departamento** (`codigo_departamento`): Indica el c√≥digo del departamento seg√∫n DIVIPOLA.  
- **C√≥digo DANE** (`codigo_dane`): C√≥digo de identificaci√≥n del municipio seg√∫n el DANE.  
- **Nombre Departamento** (`nombre_departamento`): Nombre del departamento donde se informa la atenci√≥n.  
- **Nombre Municipio** (`nombre_municipio`): Nombre del municipio donde se informa la atenci√≥n.  

## üè† Cobertura del Programa
- **Familias Atendidas en el Per√≠odo Presidencial** (`familias_periodo_presidencial`): Cantidad de familias atendidas por el programa en el municipio indicado.  
- **Personas Atendidas en el Per√≠odo Presidencial** (`personas_periodo_presidencial`): Cantidad de personas atendidas por el programa en el municipio indicado.  
- **Inversi√≥n en el Per√≠odo Presidencial** (`inversion_periodo_presidencial`): Inversi√≥n realizada por el programa en el municipio indicado.  

## üèõÔ∏è Informaci√≥n del Programa
- **Nombre del Per√≠odo Presidencial** (`nombre_periodopresidencial`): Nombre del per√≠odo presidencial atendido.  
- **Nombre del Programa de Atenci√≥n** (`nombre_programa_salida`): Nombre del programa que realiz√≥ la atenci√≥n.  
- **Descripci√≥n** (`descripcion`): Descripci√≥n del funcionamiento del programa.  
- **Entidad** (`entidad`): Nombre de la entidad a la cual pertenece el programa.  
- **Poblaci√≥n Objetivo** (`poblacion_objetivo`): Indica la poblaci√≥n a la cual est√° enfocada la atenci√≥n.  

## üí∞ Informaci√≥n Financiera
- **Pagos** (`pagos`): Indica la cantidad de pagos que se han realizado.  
- **Corte** (`corte`): Indica el corte con el cual se publica la informaci√≥n.

### **üî¢ Tipos de Datos üî†**
"""

#Identificar las variables del dataset
print("Las variables del dataset son: \n")
print(inversion.dtypes)

"""### **üìä Analisis Estad√≠stico y Gr√°ficos**

###**Estad√≠sticas** **generales**
"""

# Obtener estad√≠sticas generales de las columnas n√∫mericas
inversion.describe()

#Valores nulos
inversion.isnull().sum()

#Valores √∫nicos
inversion.nunique()

# Contar registros duplicados en todo el dataset
duplicados = internet.duplicated()
print(f"Total de filas duplicadas: {duplicados.sum()}")

"""###**Gr√°ficas**"""

#Departamentos con Mayor Inversi√≥n
top_inversion_departamentos = inversion.groupby("Nombre_Municipio")["Inversion_Periodo_Presidencial"].sum().sort_values(ascending=False).head(10)
plt.figure(figsize=(12, 5))
top_inversion_departamentos.plot(kind="bar", color="orange")
plt.title("Inversi√≥n Total por Departamento")
plt.xlabel("Departamento")
plt.ylabel("Inversi√≥n (Miles de Millones)")
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Seleccionar solo las columnas num√©ricas m√°s relevantes
numeric_columns = ['Familias_Periodo_Presidencial', 'Personas_Periodo_Presidencial',
                   'Inversion_Periodo_Presidencial', 'Pagos']

# Crear la figura y los subgr√°ficos
fig, axes = plt.subplots(nrows=1, ncols=len(numeric_columns), figsize=(15, 6))

# Generar un boxplot por variable num√©rica
for i, col in enumerate(numeric_columns):
    sns.boxplot(y=inversion[col], ax=axes[i])
    axes[i].set_title(col)
    axes[i].set_ylabel("Valores")

# Ajustar el espacio entre gr√°ficos
plt.tight_layout()
plt.show()

#¬¥Programa de Inversion
plt.figure(figsize=(12, 5))
sns.countplot(y=inversion["Nombre_Programa_Salida"], order=inversion["Nombre_Programa_Salida"].value_counts().index, palette="viridis")
plt.title("N√∫mero de Atenciones por Programa")
plt.xlabel("Cantidad")
plt.ylabel("Programa")
plt.show()

#Matriz de correlaci√≥n
corr_matrix = inversion.select_dtypes(include=['number']).corr()
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Matriz de Correlaci√≥n")
plt.show()

"""---
## **Resultados ICFES 11**

### üìöDescripci√≥n general del contenido de los conjuntos de datos  
- Este conjunto de datos contiene informaci√≥n sobre los resultados educativos de los estudiantes en Colombia, con variables relacionadas con su identificaci√≥n, ubicaci√≥n, caracter√≠sticas sociodemogr√°ficas y puntajes en distintas √°reas evaluadas.  

- Incluye detalles sobre los colegios, as√¨ como datos familiares y socioecon√≥mico, el conjunto de datos incluye puntajes en ingl√©s, matem√°ticas, lectura cr√≠tica, ciencias naturales y sociales, adem√°s del puntaje global obtenido en la evaluaci√≥n**. Esta informaci√≥n permite analizar la relaci√≥n entre factores sociodemogr√°ficos y el desempe√±o acad√©mico, facilitando estudios sobre calidad educativa y equidad en el acceso a oportunidades.
"""

# Mostrar las primeras filas del dataset
display(icfes_bogota.head())

# Mostrar la cantidad de filas y columnas
icfes_bogota.shape

"""### **üìå Compresi√≥n de los Atributos del Dataset**
## üìÖ Informaci√≥n General
- **PERIODO** (`periodo`): Periodo de los resultados.  
- **ESTU_TIPODOCUMENTO** (`estu_tipodocumento`): Tipo de documento del examinando.  
- **ESTU_CONSECUTIVO** (`estu_consecutivo`): Identificador √∫nico del examinando.  

## üè´ Informaci√≥n del Colegio
- **COLE_AREA_UBICACION** (`cole_area_ubicacion`): Ubicaci√≥n de la sede.  
- **COLE_BILINGUE** (`cole_bilingue`): ¬øEs colegio biling√ºe?  
- **COLE_CALENDARIO** (`cole_calendario`): Calendario del establecimiento.  
- **COLE_CARACTER** (`cole_caracter`): Car√°cter del establecimiento.  
- **COLE_COD_DANE_ESTABLECIMIENTO** (`cole_cod_dane_establecimiento`): C√≥digo DANE del establecimiento.  
- **COLE_COD_DANE_SEDE** (`cole_cod_dane_sede`): C√≥digo DANE de la sede.  
- **COLE_COD_DEPTO_UBICACION** (`cole_cod_depto_ubicacion`): Departamento de la sede.  
- **COLE_COD_MCPIO_UBICACION** (`cole_cod_mcpio_ubicacion`): C√≥digo del municipio de la sede.  
- **COLE_CODIGO_ICFES** (`cole_codigo_icfes`): C√≥digo ICFES del establecimiento.  
- **COLE_DEPTO_UBICACION** (`cole_depto_ubicacion`): Departamento de la sede.  
- **COLE_GENERO** (`cole_genero`): G√©nero del establecimiento.  
- **COLE_JORNADA** (`cole_jornada`): Jornada de la sede.  
- **COLE_MCPIO_UBICACION** (`cole_mcpio_ubicacion`): Municipio de la sede.  
- **COLE_NATURALEZA** (`cole_naturaleza`): Naturaleza del establecimiento.  
- **COLE_NOMBRE_ESTABLECIMIENTO** (`cole_nombre_establecimiento`): Nombre del establecimiento.  
- **COLE_NOMBRE_SEDE** (`cole_nombre_sede`): Nombre de la sede.  
- **COLE_SEDE_PRINCIPAL** (`cole_sede_principal`): ¬øEs la sede principal?  

## üìç Ubicaci√≥n del Examen y Residencia
- **ESTU_COD_DEPTO_PRESENTACION** (`estu_cod_depto_presentacion`): C√≥digo del departamento de presentaci√≥n del examen.  
- **ESTU_COD_MCPIO_PRESENTACION** (`estu_cod_mcpio_presentacion`): C√≥digo del municipio de presentaci√≥n del examen.  
- **ESTU_COD_RESIDE_DEPTO** (`estu_cod_reside_depto`): C√≥digo del departamento de residencia del examinando.  
- **ESTU_COD_RESIDE_MCPIO** (`estu_cod_reside_mcpio`): C√≥digo del municipio de residencia del examinando.  
- **ESTU_DEPTO_PRESENTACION** (`estu_depto_presentacion`): Departamento de presentaci√≥n del examen.  
- **ESTU_DEPTO_RESIDE** (`estu_depto_reside`): Departamento de residencia del examinando.  
- **ESTU_MCPIO_PRESENTACION** (`estu_mcpio_presentacion`): Municipio de presentaci√≥n del examen.  
- **ESTU_MCPIO_RESIDE** (`estu_mcpio_reside`): Municipio de residencia del examinando.  

## üë§ Informaci√≥n del Examinando
- **ESTU_ESTADOINVESTIGACION** (`estu_estadoinvestigacion`): ¬øPermite usar sus datos para investigaciones?  
- **ESTU_ESTUDIANTE** (`estu_estudiante`): "S" si es estudiante o "N" si es individual.  
- **ESTU_FECHANACIMIENTO** (`estu_fechanacimiento`): Fecha de nacimiento del examinando.  
- **ESTU_GENERO** (`estu_genero`): G√©nero del examinando.  
- **ESTU_NACIONALIDAD** (`estu_nacionalidad`): Nacionalidad del examinando.  
- **ESTU_PAIS_RESIDE** (`estu_pais_reside`): Pa√≠s de residencia del examinando.  
- **ESTU_PRIVADO_LIBERTAD** (`estu_privado_libertad`): ¬øEs privado de la libertad?  

## üè† Informaci√≥n del Hogar
- **FAMI_CUARTOSHOGAR** (`fami_cuartoshogar`): ¬øCu√°ntos cuartos tiene su hogar?  
- **FAMI_EDUCACIONMADRE** (`fami_educacionmadre`): Nivel de estudios de la madre.  
- **FAMI_EDUCACIONPADRE** (`fami_educacionpadre`): Nivel de estudios del padre.  
- **FAMI_ESTRATOVIVIENDA** (`fami_estratovivienda`): Estrato del examinando.  
- **FAMI_PERSONASHOGAR** (`fami_personashogar`): ¬øCon cu√°ntas personas vive?  
- **FAMI_TIENEAUTOMOVIL** (`fami_tieneautomovil`): ¬øTiene autom√≥vil?  
- **FAMI_TIENECOMPUTADOR** (`fami_tienecomputador`): ¬øTiene computador?  
- **FAMI_TIENEINTERNET** (`fami_tieneinternet`): ¬øTiene internet?  
- **FAMI_TIENELAVADORA** (`fami_tienelavadora`): ¬øTiene lavadora?  

## üìä Resultados del Examen
- **DESEMP_INGLES** (`desemp_ingles`): Desempe√±o en ingl√©s.  
- **PUNT_INGLES** (`punt_ingles`): Puntaje en ingl√©s.  
- **PUNT_MATEMATICAS** (`punt_matematicas`): Puntaje en matem√°ticas.  
- **PUNT_SOCIALES_CIUDADANAS** (`punt_sociales_ciudadanas`): Puntaje en sociales y ciudadanas.  
- **PUNT_C_NATURALES** (`punt_c_naturales`): Puntaje en ciencias naturales.  
- **PUNT_LECTURA_CRITICA** (`punt_lectura_critica`): Puntaje en lectura cr√≠tica.  
- **PUNT_GLOBAL** (`punt_global`): Puntaje global.

### **üî¢ Tipos de Datos üî†**
"""

#Identificar las variables del dataset
print("Las variables del dataset son: \n")
print(icfes_bogota.dtypes)

"""### **üìä Analisis Estad√≠stico y Gr√°ficos**

###**Estad√≠sticas** **generales**
"""

# Obtener estad√≠sticas generales
icfes_bogota.describe()

#Valores nulos
pobreza.isnull().sum()

#Valores √∫nicos
pobreza.nunique()

# Contar registros duplicados en todo el dataset
duplicados = internet.duplicated()
print(f"Total de filas duplicadas: {duplicados.sum()}")

"""###**Gr√°ficas**"""

#Distribuci√≥n de los Puntajes Globales ##cambiar nombres de dataset para corroborar
dataset=icfes_bogota
plt.figure(figsize=(12, 5))
sns.histplot(dataset["PUNT_GLOBAL"], bins=30, kde=True, color="blue")
plt.title("Distribuci√≥n de los Puntajes Globales")
plt.xlabel("Puntaje Global")
plt.ylabel("Frecuencia")
plt.show()

#Promedio de Puntajes por Materia
promedios = dataset[["PUNT_INGLES", "PUNT_MATEMATICAS", "PUNT_SOCIALES_CIUDADANAS",
                     "PUNT_C_NATURALES", "PUNT_LECTURA_CRITICA"]].mean()
plt.figure(figsize=(12, 5))
promedios.plot(kind="bar", color="green")
plt.title("Promedio de Puntajes por Materia")
plt.xlabel("Materia")
plt.ylabel("Puntaje Promedio")
plt.xticks(rotation=45)
plt.show()

#Distribuci√≥n del Estrato Socioecon√≥mico de los Examinandos
plt.figure(figsize=(8, 5))
sns.countplot(data=dataset, x="FAMI_ESTRATOVIVIENDA", palette="coolwarm")
plt.title("Distribuci√≥n del Estrato Socioecon√≥mico")
plt.xlabel("Estrato")
plt.ylabel("Cantidad de Examinandos")
plt.show()

#Relaci√≥n entre el Estrato y el Puntaje Global
plt.figure(figsize=(8, 6))
sns.boxplot(data=dataset, x="FAMI_ESTRATOVIVIENDA", y="PUNT_GLOBAL", palette="coolwarm")
plt.title("Relaci√≥n entre Estrato y Puntaje Global")
plt.xlabel("Estrato")
plt.ylabel("Puntaje Global")
plt.show()

#Diferencia de Puntajes por G√©nero
plt.figure(figsize=(8, 6))
sns.boxplot(data=dataset, x="ESTU_GENERO", y="PUNT_GLOBAL", palette="muted")
plt.title("Diferencia de Puntajes Globales por G√©nero")
plt.xlabel("G√©nero")
plt.ylabel("Puntaje Global")
plt.show()

"""---
## **Filtros Limpieza y transformaci√≥n inicial**

En esta secci√≥n, se realizar√° un proceso de limpieza, filtrado y transformaci√≥n inicial sobre los diferentes conjuntos de datos utilizados en el an√°lisis. El objetivo principal es garantizar la calidad de los datos eliminando inconsistencias, manejando valores nulos y eliminando valores at√≠picos que puedan afectar los an√°lisis posteriores.

Para ello, se aplicar√°n los siguientes pasos en cada uno de los nueve conjuntos de datos:

**Manejo de valores nulos:**



*   Se identificar√° el porcentaje de valores faltantes en cada variable.

*   Se eliminar√°n columnas con m√°s del 35% de valores nulos, ya que pueden afectar la calidad del an√°lisis.

*  Se imputar√°n los valores faltantes de las variables num√©ricas utilizando la media de la columna.

*   Se imputar√°n los valores faltantes de las variables categ√≥ricas utilizando la moda (valor m√°s frecuente).


**Eliminaci√≥n de valores at√≠picos**


*   Se analizar√° la distribuci√≥n de los valores en cada variable num√©rica.

*    Se utilizar√° el m√©todo del rango intercuart√≠lico (IQR) para detectar valores extremos y eliminarlos, reduciendo el impacto de datos an√≥malos en el an√°lisis.

### **Conjunto de datos `Icfes_bogota`**

**Limpieza de datos**
"""

# 1. Manejo de valores nulos
df1=icfes_bogota
# Columnas con m√°s del 35% de valores nulos que se eliminar√°n
cols_to_drop = ["PUNT_SOCIALES_CIUDADANAS", "PUNT_C_NATURALES", "PUNT_LECTURA_CRITICA", "PUNT_GLOBAL"]
df1.drop(columns=cols_to_drop, inplace=True)

# Imputaci√≥n de valores num√©ricos con la media
df1.fillna(df1.mean(numeric_only=True), inplace=True)

# Imputaci√≥n de valores categ√≥ricos con la moda
categorical_cols = df1.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df1[col].fillna(df1[col].mode()[0], inplace=True)

# 2. Detecci√≥n y eliminaci√≥n de valores at√≠picos (usando IQR)
numeric_cols = df1.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    Q1 = df1[col].quantile(0.25)
    Q3 = df1[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df1 = df1[(df1[col] >= lower_bound) & (df1[col] <= upper_bound)]

# Guardar el dataset limpio
icfes_bogota_limpio=df1

#Verificar el n√∫mero de campos vacios
cantidad_nulos1 = icfes_bogota_limpio.isnull().sum()  # conteo de los nulos
print("Cantidad de campos vacios en cada columna: \n", cantidad_nulos1)

icfes_bogota_limpio.shape

"""En el dataset de resultados de ICFES Bogot√°, se identificaron valores nulos en varias variables, algunas con m√°s del 35% de datos faltantes. Se eliminaron las columnas "PUNT_SOCIALES_CIUDADANAS", "PUNT_C_NATURALES", "PUNT_LECTURA_CRITICA" y "PUNT_GLOBAL", ya que el alto porcentaje de valores nulos afectar√≠a la calidad del an√°lisis. Para las dem√°s variables, los valores faltantes num√©ricos fueron imputados con la media, mientras que los categ√≥ricos fueron reemplazados con la moda. Adem√°s, se aplic√≥ el m√©todo IQR para eliminar valores at√≠picos en las variables num√©ricas, mejorando as√≠ la representatividad del conjunto de datos.

### **Conjunto de datos `Icfes_medellin`**

**Limpieza de datos**
"""

# Ver las primeras filas
print(icfes_medellin.head())

# Ver informaci√≥n general (tipos de datos, valores nulos, etc.)
print(icfes_medellin.info())

# Ver cu√°ntos valores nulos hay por columna
print(icfes_medellin.isnull().sum())

# Ver duplicados
print(f"Duplicados: {icfes_medellin.duplicated().sum()}")

icfes_medellin_viejo = icfes_medellin

# 1. Eliminar filas con valores nulos
icfes_medellin.dropna(inplace=True)

# 2. Convertir las columnas de puntajes a tipo float (por si tienen valores err√≥neos)
cols_numericas = [
    "PUNT_INGLES", "PUNT_MATEMATICAS", "PUNT_SOCIALES_CIUDADANAS",
    "PUNT_C_NATURALES", "PUNT_LECTURA_CRITICA", "PUNT_GLOBAL"
]
icfes_medellin[cols_numericas] = icfes_medellin[cols_numericas].apply(pd.to_numeric, errors="coerce")

# 3. Filtrar valores fuera de los rangos esperados
icfes_medellin = icfes_medellin[
    (icfes_medellin["PUNT_INGLES"].between(0, 100)) &
    (icfes_medellin["PUNT_MATEMATICAS"].between(0, 100)) &
    (icfes_medellin["PUNT_SOCIALES_CIUDADANAS"].between(0, 100)) &
    (icfes_medellin["PUNT_C_NATURALES"].between(0, 100)) &
    (icfes_medellin["PUNT_LECTURA_CRITICA"].between(0, 100)) &
    (icfes_medellin["PUNT_GLOBAL"].between(0, 500))
]

# 4. Verificar cambios
print(icfes_medellin.info())
print(icfes_medellin.isnull().sum())
print(f"Duplicados: {icfes_medellin.duplicated().sum()}")

import matplotlib.pyplot as plt
import seaborn as sns

# Crear una figura con dos gr√°ficos (antes y despu√©s)
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Dataset original sin limpiar
sns.boxplot(data=icfes_medellin_viejo[cols_numericas], ax=axes[0])
axes[0].set_title("Antes de la Limpieza (Con Outliers)")
axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)

# Dataset limpio sin valores at√≠picos
sns.boxplot(data=icfes_medellin[cols_numericas], ax=axes[1])
axes[1].set_title("Despu√©s de la Limpieza (Sin Outliers)")
axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)

plt.tight_layout()
plt.show()

"""En general el dataset estaba bastante limpio, sin embargo tenia muchos valores nulos necesarios para el desarrollo del proyecto

### **Conjunto de datos `Icfes_neiva`**

**Limpieza de datos**
"""

# Ver las primeras filas
print(icfes_neiva.head())

# Ver informaci√≥n general (tipos de datos, valores nulos, etc.)
print(icfes_neiva.info())

# Ver cu√°ntos valores nulos hay por columna
print(icfes_neiva.isnull().sum())

# Ver duplicados
print(f"Duplicados: {icfes_neiva.duplicated().sum()}")

icfes_neiva_viejo = icfes_neiva

# Verificar informaci√≥n inicial
info_neiva = icfes_neiva.info()
nulos_neiva = icfes_neiva.isnull().sum()
duplicados_neiva = icfes_neiva.duplicated().sum()

# Eliminar filas con valores nulos
icfes_neiva_cleaned = icfes_neiva.dropna()

# Filtrar valores at√≠picos en puntajes (0-100 por √°rea, 0-500 global)
columns_puntajes = ["PUNT_INGLES", "PUNT_MATEMATICAS", "PUNT_SOCIALES_CIUDADANAS", "PUNT_C_NATURALES", "PUNT_LECTURA_CRITICA"]
for col in columns_puntajes:
    icfes_neiva_cleaned = icfes_neiva_cleaned[(icfes_neiva_cleaned[col] >= 0) & (icfes_neiva_cleaned[col] <= 100)]

icfes_neiva_cleaned = icfes_neiva_cleaned[(icfes_neiva_cleaned["PUNT_GLOBAL"] >= 0) & (icfes_neiva_cleaned["PUNT_GLOBAL"] <= 500)]

# Eliminar duplicados
icfes_neiva_cleaned = icfes_neiva_cleaned.drop_duplicates()

# Resumen de cambios
nulos_despues = icfes_neiva_cleaned.isnull().sum()
duplicados_despues = icfes_neiva_cleaned.duplicated().sum()
shape_original = icfes_neiva.shape
shape_limpio = icfes_neiva_cleaned.shape

shape_original, nulos_neiva, duplicados_neiva, shape_limpio, nulos_despues, duplicados_despues

import matplotlib.pyplot as plt
import seaborn as sns

# Crear una figura con dos gr√°ficos (antes y despu√©s)
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Dataset original sin limpiar
sns.boxplot(data=icfes_neiva_viejo[cols_numericas], ax=axes[0])
axes[0].set_title("Antes de la Limpieza (Con Outliers)")
axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)

# Dataset limpio sin valores at√≠picos
sns.boxplot(data=icfes_neiva_cleaned[cols_numericas], ax=axes[1])
axes[1].set_title("Despu√©s de la Limpieza (Sin Outliers)")
axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)

plt.tight_layout()
plt.show()

"""En general el dataset estaba bastante limpio, sin embargo tenia muchos valores nulos necesarios para el desarrollo del proyecto. Ademas se ecnotraron alguno datos por fuera de los limites de puntuacion, por ejemplo en alguna area por encima de 100 el cual es el maximo

### **Conjunto de datos `Icfes_armenia`**

**Limpieza de datos**
"""

# Ver las primeras filas
print(icfes_armenia.head())

# Ver informaci√≥n general (tipos de datos, valores nulos, etc.)
print(icfes_armenia.info())

# Ver cu√°ntos valores nulos hay por columna
print(icfes_armenia.isnull().sum())

# Ver duplicados
print(f"Duplicados: {icfes_armenia.duplicated().sum()}")

icfes_armenia_viejo = icfes_armenia

# Eliminar filas con valores nulos en las columnas relevantes
columnas_relevantes = [
    "PUNT_INGLES", "PUNT_MATEMATICAS", "PUNT_SOCIALES_CIUDADANAS",
    "PUNT_C_NATURALES", "PUNT_LECTURA_CRITICA", "PUNT_GLOBAL"
]
icfes_armenia = icfes_armenia.dropna(subset=columnas_relevantes)

# Convertir las columnas de puntajes a num√©ricas
for col in columnas_relevantes:
    icfes_armenia[col] = pd.to_numeric(icfes_armenia[col], errors="coerce")

# Filtrar los datos at√≠picos (rango v√°lido: 0-100 para √°reas, 0-500 para puntaje global)
icfes_armenia = icfes_armenia[
    (icfes_armenia["PUNT_INGLES"].between(0, 100)) &
    (icfes_armenia["PUNT_MATEMATICAS"].between(0, 100)) &
    (icfes_armenia["PUNT_SOCIALES_CIUDADANAS"].between(0, 100)) &
    (icfes_armenia["PUNT_C_NATURALES"].between(0, 100)) &
    (icfes_armenia["PUNT_LECTURA_CRITICA"].between(0, 100)) &
    (icfes_armenia["PUNT_GLOBAL"].between(0, 500))
]

# Verificar la limpieza
icfes_armenia.info(), icfes_armenia.describe()

import matplotlib.pyplot as plt
import seaborn as sns

# Crear una figura con dos gr√°ficos (antes y despu√©s)
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Dataset original sin limpiar
sns.boxplot(data=icfes_armenia_viejo[cols_numericas], ax=axes[0])
axes[0].set_title("Antes de la Limpieza (Con Outliers)")
axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)

# Dataset limpio sin valores at√≠picos
sns.boxplot(data=icfes_armenia[cols_numericas], ax=axes[1])
axes[1].set_title("Despu√©s de la Limpieza (Sin Outliers)")
axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)

plt.tight_layout()
plt.show()

"""En general el dataset estaba bastante limpio, sin embargo tenia muchos valores nulos necesarios para el desarrollo del proyecto. Ademas se ecnotraron alguno datos por fuera de los limites de puntuacion, por ejemplo en alguna area por encima de 100 el cual es el maximo

### **Conjunto de datos `Pobreza`**

**Limpieza de datos**
"""

#Verificar el n√∫mero de campos vacios
cantidad_nulos = pobreza.isnull().sum()  # conteo de los nulos
#Calcular el porcentaje de campos vacios por columna
cantidad_registros = pobreza.shape[0]
print("Cantidad de registros: ", pobreza.shape[0])
Porcentaje = cantidad_nulos/cantidad_registros*100
print("Porcentaje de campos vacios por columna: \n", Porcentaje)

# 1. Manejo de valores nulos
df_pobreza=pobreza
# Identificar el porcentaje de valores nulos por columna
missing_percentage = df_pobreza.isnull().sum() / len(df_pobreza) * 100

# Eliminar columnas con m√°s del 35% de valores nulos
cols_to_drop = missing_percentage[missing_percentage > 35].index
df_pobreza.drop(columns=cols_to_drop, inplace=True)

# Imputaci√≥n de valores num√©ricos con la media
numeric_cols = df_pobreza.select_dtypes(include=[np.number]).columns
df_pobreza[numeric_cols] = df_pobreza[numeric_cols].apply(lambda x: x.fillna(x.mean()))

# Imputaci√≥n de valores categ√≥ricos con la moda
categorical_cols = df_pobreza.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df_pobreza[col].fillna(df_pobreza[col].mode()[0], inplace=True)

# 2. Detecci√≥n y eliminaci√≥n de valores at√≠picos (usando IQR)
numeric_cols = df_pobreza.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    Q1 = df_pobreza[col].quantile(0.25)
    Q3 = df_pobreza[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_pobreza = df_pobreza[(df_pobreza[col] >= lower_bound) & (df_pobreza[col] <= upper_bound)]

# Guardar el dataset limpio
pobreza_limpio=df_pobreza

pobreza_limpio.info()

"""El dataset de pobreza present√≥ un alto porcentaje de valores nulos en varias columnas, algunas con m√°s del 95% de datos faltantes. Para mejorar la calidad del an√°lisis, se eliminaron las columnas con m√°s del 35% de valores nulos. Para las variables restantes, los valores num√©ricos faltantes fueron reemplazados con la media, y los categ√≥ricos con la moda. Tambi√©n se aplic√≥ el m√©todo IQR para la detecci√≥n y eliminaci√≥n de valores at√≠picos en las variables num√©ricas, asegurando una distribuci√≥n m√°s representativa.

### **Conjunto de datos `Inversi√≥n`**

**Limpieza de datos**
"""

#Verificaci√≥n de datos Atipicos

plt.figure(figsize=(8,5))
sns.boxplot(x=inversion["Inversion_Periodo_Presidencial"])
plt.title("Distribuci√≥n de Inversion_Periodo_Presidencial")
plt.show()

Q1 = inversion["Inversion_Periodo_Presidencial"].quantile(0.25)
Q3 = inversion["Inversion_Periodo_Presidencial"].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

inversion_limpio = inversion[(inversion["Inversion_Periodo_Presidencial"] >= lower_bound) &
                             (inversion["Inversion_Periodo_Presidencial"] <= upper_bound)]

plt.figure(figsize=(8,5))
sns.boxplot(x=inversion_limpio["Inversion_Periodo_Presidencial"])
plt.title("Distribuci√≥n de Inversion_Periodo_Presidencial")
plt.show()

"""El dataset de inversi√≥n no presentaba valores nulos, por lo que no fue necesario realizar imputaciones. Sin embargo, se verificaron valores at√≠picos en la variable Inversion_Periodo_Presidencial mediante el m√©todo IQR, asegurando que no haya registros que distorsionen el an√°lisis. Tambi√©n se evalu√≥ la inversi√≥n per c√°pita como una posible m√©trica adicional para futuros an√°lisis.

### **Conjunto de datos `Matriculas`**

**Limpieza de datos**
"""

import numpy as np

# Definir el mapeo de c√≥digos a nombres de departamentos
mapeo_departamentos = {
    5: "Antioquia",
    11: "Bogot√° D.C.",
    41: "Huila",
    63: "Quind√≠o"
}

# Reemplazar los valores en la columna "Nombre del Departamento" basados en "C√≥digo del Departamento"
matriculas["Nombre del Departamento"] = matriculas["C√≥digo delDepartamento"].replace(mapeo_departamentos)

# Verificar si los cambios se aplicaron
print(matriculas.head())

"""En general estaba bastante limpio, solo se le realizo el cambio del codigo al nombre del departamento, ya que estaba en la columna codigo departamento y nombre del departamento ambas con codigo y sin el nomnbre

### **Conjunto de datos `Educaci√≥n`**

**Limpieza de datos**
"""

# Lista de columnas a eliminar
columnas_a_eliminar = [
    "REPITENCIA_TRANSICI√ìN", "REPITENCIA_PRIMARIA", "REPITENCIA_MEDIA", "REPITENCIA",
    "TAMA√ëO_PROMEDIO_DE_GRUPO", "SEDES_CONECTADAS_A_INTERNET",
    "REPROBACI√ìN_MEDIA", "REPROBACI√ìN_PRIMARIA", "REPROBACI√ìN_TRANSICI√ìN", "REPROBACI√ìN",
    "APROBACI√ìN", "APROBACI√ìN_MEDIA", "APROBACI√ìN_PRIMARIA", "APROBACI√ìN_TRANSICI√ìN",
    "DESERCI√ìN", "DESERCI√ìN_MEDIA", "DESERCI√ìN_PRIMARIA", "DESERCI√ìN_TRANSICI√ìN",
    "COBERTURA_BRUTA_MEDIA", "COBERTURA_BRUTA_PRIMARIA", "COBERTURA_BRUTA_TRANSICI√ìN", "COBERTURA_BRUTA",
    "COBERTURA_NETA_MEDIA", "COBERTURA_NETA_PRIMARIA", "COBERTURA_NETA_TRANSICI√ìN", "COBERTURA_NETA",
    "C√ìDIGO_ETC", "ETC"
]

# Eliminar las columnas
educacion_limpio = educacion.drop(columns=columnas_a_eliminar, errors="ignore")

# Verificar la nueva estructura del dataset
print(educacion_limpio.info())

"""En general el dataset tenia muchas columna irrelevantes para el proyecto, algunas estas presentaban datos de transision y primaria, lo cual no es relevante. A la vez, presentaba incongruencias es otras columnas que reflejaban datos sin sentido, como el total de estudiantes siendo menor que los estudiantes que cursan en bachillerato. Tambien, hubo columnas con un alto porcentaje de datos nulos. Se eliminaron estas columnas que afectaban el desarrollo del proyecto

### **Conjunto de datos `Internet`**

**Limpieza de datos**
"""

internet.info()

# 1. Creaci√≥n de m√©trica de accesos a internet por cada 1000 habitantes
df_internet=internet
df_internet["Internet_per_capita"] = (df_internet["No. ACCESOS FIJOS A INTERNET"] * 1000) / df_internet["POBLACI√ìN DANE"]

# 2. Detecci√≥n y eliminaci√≥n de valores at√≠picos en la nueva m√©trica


Q1 = df_internet["Internet_per_capita"].quantile(0.25)
Q3 = df_internet["Internet_per_capita"].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
df_internet = df_internet[(df_internet["Internet_per_capita"] >= lower_bound) &
                           (df_internet["Internet_per_capita"] <= upper_bound)]

# Visualizaci√≥n de la distribuci√≥n despu√©s de la limpieza
plt.figure(figsize=(10, 5))
sns.histplot(df_internet["Internet_per_capita"], bins=30, kde=True)
plt.title("Distribuci√≥n de Internet per c√°pita despu√©s de limpieza")
plt.show()

# Guardar el dataset limpio
internet_limpio=df_internet

"""El dataset de acceso a internet no presentaba valores nulos, por lo que no fue necesario realizar imputaciones. Sin embargo, para mejorar su utilidad en el an√°lisis, se realizaron las siguientes transformaciones:

**Creaci√≥n de la m√©trica de acceso a internet per c√°pita:**

  Para comparar de manera equitativa el acceso a internet entre municipios con diferentes tama√±os poblacionales, se cre√≥ una nueva variable que calcula los accesos a internet por cada 1,000 habitantes.
  Esta transformaci√≥n permite un an√°lisis m√°s representativo de la cobertura del servicio en cada municipio.

**Eliminaci√≥n de valores at√≠picos:**

Se utiliz√≥ el m√©todo IQR (Rango Intercuartil) para identificar y eliminar valores extremadamente altos o bajos en la m√©trica de acceso a internet per c√°pita.
Esto ayuda a evitar distorsiones en el an√°lisis y a mejorar la representatividad de los datos.

Estas mejoras garantizan que los datos sean m√°s confiables y adecuados para su an√°lisis posterior.
"""